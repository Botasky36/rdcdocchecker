import streamlit as st
from utils.reader import extract_text_from_pdf, extract_text_from_docx
from utils.grammar import check_grammar
from utils.format_checker import check_format
from utils.readability import check_readability
from utils.structure_summary import summarize_structure

import re
from PIL import Image
from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import base64
from fpdf import FPDF

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏´‡∏ô‡πâ‡∏≤
st.set_page_config(page_title="Research Document Checker", layout="wide")

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πÑ‡∏ï‡∏•‡πå CSS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≠‡∏á‡∏ó‡∏±‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®
st.markdown("""
    <style>
        .stApp {
            background-color: #e6f0fa;
        }
        h1, h2, h3, h4 {
            color: #003366;
        }
        .stButton > button {
            background-color: #005580;
            color: white;
            border-radius: 8px;
            font-weight: bold;
        }
        details summary {
            background-color: #cce0f5;
            color: #003366;
            padding: 10px;
            font-size: 18px;
            border-radius: 5px;
        }
        .stMarkdown, .stText, .stSubheader {
            color: #002147;
        }
    </style>
""", unsafe_allow_html=True)

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏•‡πÇ‡∏Å‡πâ‡∏®‡∏ß‡∏≠.‡∏ó‡∏≠.
logo = Image.open("logo_rtaf.png")
st.image(logo, width=100)

# ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å
st.title("üìò ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢")
st.subheader("‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÄ‡πÄ‡∏•‡∏∞‡∏≠‡∏ß‡∏Å‡∏≤‡∏®‡∏Å‡∏≠‡∏á‡∏ó‡∏±‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
def remove_extra_spaces(text):
    return re.sub(r'\s{2,}', ' ', text)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô export PDF ‡∏ú‡πà‡∏≤‡∏ô FPDF + Streamlit
def export_report_streamlit(text_dict):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size=12)

    pdf.cell(200, 10, txt="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢", ln=True, align='C')

    for section, content in text_dict.items():
        pdf.ln(8)
        pdf.set_font("Arial", style="B", size=12)
        pdf.cell(200, 10, txt=section, ln=True)
        pdf.set_font("Arial", size=11)

        text = str(content)
        lines = text.split('\n')
        for line in lines:
            pdf.multi_cell(0, 10, txt=line)

    buffer = BytesIO()
    pdf.output(buffer)
    buffer.seek(0)

    b64 = base64.b64encode(buffer.read()).decode()
    href = f'<a href="data:application/pdf;base64,{b64}" download="report.pdf">üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î PDF ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô</a>'
    st.markdown(href, unsafe_allow_html=True)

# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠ DOCX", type=["pdf", "docx"])

if uploaded_file:
    if uploaded_file.name.endswith(".pdf"):
        text = extract_text_from_pdf(uploaded_file)
    else:
        text = extract_text_from_docx(uploaded_file)

    st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

    cleaned_text = remove_extra_spaces(text)

    with st.expander("üî§ ‡∏ï‡∏£‡∏ß‡∏à‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î"):
        msg, matches = check_grammar(cleaned_text)
        st.write(msg)
        for m in matches[:5]:
            st.markdown(f"- ‚ùó {m['error_text']} ‚Üí {', '.join(m['suggestions'])} ({m['message']})")

    grammar_data = matches

    with st.expander("üìê ‡∏ï‡∏£‡∏ß‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"):
        format_result = check_format(cleaned_text)
        for section, result in format_result.items():
            st.write(f"- {section}: {result}")

    with st.expander("üìä ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô"):
        readability = check_readability(cleaned_text)
        for k, v in readability.items():
            st.write(f"{k}: {v}")

    with st.expander("üß† ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"):
        summary = summarize_structure(cleaned_text)
        for title, content in summary.items():
            st.subheader(title)
            st.write(content[:500] + "..." if len(content) > 500 else content)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö dict
    summary_data = {
        "üî§ ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î": msg + "\n" + "\n".join([
            f"- {item['error_text']} ‚Üí {', '.join(item['suggestions'])}" for item in grammar_data[:10]
        ]),
        "üìê ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£": "\n".join([f"{k}: {v}" for k, v in format_result.items()]),
        "üìä ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô": "\n".join([f"{k}: {v}" for k, v in readability.items()]),
        "üß† ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö": "\n".join([f"{k}: {v[:150]}..." for k, v in summary.items()])
    }

    export_report_streamlit(summary_data)

# üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤
st.markdown("""
<hr style="border:1px solid #003366; margin-top:40px; margin-bottom:10px">
<div style="text-align: center; color: #003366; font-size: 14px;">
    üìû ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö<br>
    ‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤: ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏ß‡∏Å‡∏≤‡∏® ‡∏Å‡∏≠‡∏á‡∏ó‡∏±‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®<br>
    ‡∏≠‡∏µ‡πÄ‡∏°‡∏•: <a href=\"mailto:piyapan_th@rtaf.mi.th\">piyapan_th@rtaf.mi.th</a><br>
    ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå: 02-534-4849 ‡∏ï‡πà‡∏≠ 12345
</div>
""", unsafe_allow_html=True)

