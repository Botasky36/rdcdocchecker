import language_tool_python
from pythainlp.spell import correct
from pythainlp.tokenize import word_tokenize
import re

# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
def detect_language(text):
    thai_chars = len(re.findall(r'[‡∏Å-‡πô]', text))
    english_chars = len(re.findall(r'[a-zA-Z]', text))
    return 'th' if thai_chars > english_chars else 'en'

# ‡∏ï‡∏£‡∏ß‡∏à‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå/‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

def check_grammar(text):
    lang = detect_language(text)
    results = []

    if lang == 'en':
        tool = language_tool_python.LanguageTool('en-US')
        matches = tool.check(text)
        for m in matches:
            results.append({
                'error_text': text[m.offset : m.offset + m.errorLength],
                'suggestions': m.replacements,
                'message': m.message,
                'offset': m.offset
            })
        return f"üî§ ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©: ‡∏û‡∏ö {len(results)} ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", results

    else:  # ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        words = word_tokenize(text, engine='newmm')
        for word in words:
            if re.search(r'[‡∏Å-‡πô]', word):
                corrected = correct(word)
                if word != corrected:
                    results.append({
                        'error_text': word,
                        'suggestions': [corrected],
                        'message': "‡∏Ñ‡∏≥‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î"
                    })
        return f"üî§ ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: ‡∏û‡∏ö {len(results)} ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î", results
